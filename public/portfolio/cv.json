{
  "$schema": "https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/schema.json",
  "basics": {
    "name": "Arnaud TANGUY",
    "label": "Research engineer at Laboratoire d'Informatique et de Microélectronique de l'Université de Montpellier (LIRMM)",
    "image": "",
    "email": "arn.tanguy@gmail.com",
    "phone": "+33 7 62 70 55 79",
    "url": "https://arntanguy.fr",
    "summary": "I'm a research engineer in the field of Humanoid Robotics, with a strong background in dense visual Simultaneous Localization and Mapping (SLAM).",
    "location": {
      "countryCode": "FR",
      "address": "3035 Avenue des Moulins, 34080 Montpellier, France"
    },
    "profiles": [
      {
        "network": "LinkedIn",
        "username": "arnaud-tanguy",
        "url": "https://www.linkedin.com/in/arnaud-tanguy/"
      }
    ]
  },
  "work": [
    {
      "name": "Centre national de la recherche scientifique",
      "position": "Robotics Engineer - Humanoid Robotics",
      "startDate": "2021-10-31",
      "endDate": "2024-04-31",
      "highlights": ["Live robot dance performance on stage at Centre des Arts Enghain-les-Bains", "ANA Avatar XPrize Finalist", "Large-scale loco-manipulation demonstration on-sight for an industrial partner (confidential)"],
      "url": "https://www.linkedin.com/company/cnrs/",
      "location": "Montpellier, Occitanie, France",
      "keywords": ["C++", "Humanoid Robotics", "Unity", "Augmented Reality", "ANA Avatar XPRIZE", "mc_rtc framework"]
    },
    {
      "name": "National Institute of Advanced Industrial Science and Technology (AIST)",
      "position": "Research Engineer - Humanoid Robotics",
      "startDate": "2019-11-30",
      "endDate": "2021-04-30",
      "highlights": ["Responsible for the unification of two control frameworks: mc_rtc and HMC", "Assisting students and researchers", "Responsible for experiments and demonstrations on the robots (HRP-5P, HRP-2Kai, Sawyer, Panda, etc)"],
      "url": "https://www.linkedin.com/company/aist/",
      "location": "Tsukuba, Japan",
      "keywords": ["C++", "Humanoid Robotics", "Unity", "Augmented Reality", "ANA Avatar XPrize", "mc_rtc framework"]
    },
    {
      "name": "Centre national de la recherche scientifique",
      "position": "Research Engineer in Humanoid Robotics",
      "startDate": "2018-10-31",
      "endDate": "2019-11-30",
      "highlights": ["Responsible for the integration of visual SLAM for robust localisation of the HRP4 Humanoid Robot, notably withing an Airbus aircraft for the final demonstration of the H2020 COMANOID project", "Responsible for the development of all experiments performed on the HR4 at LIRMM", "Integration of new methods and tools within our control framework"],
      "url": "https://www.linkedin.com/company/cnrs/",
      "location": "Montpellier, France",
      "keywords": ["C++", "Humanoid Robotics", "SLAM", "COMANOID H2020", "mc_rtc framework"]
    },
    {
      "name": "CNRS - Centre national de la recherche scientifique",
      "position": "PhD in Humanoid Robotics and Computer Vision",
      "startDate": "2014-10-31",
      "endDate": "2018-11-30",
      "highlights": ["Improved robot-environment interactions and reliability with state-of-the-art real-time visual localization and mapping from color and depth images (SLAM)", "Under CNRS contract funded by COMANOID European research project", "Worked in three major international labs: Joint Robotics Laboratory - Tsukuba, Japan ; LIRMM - Montpellier, France ; I3S-CNRS - Sophia-Antipolis, France", "Obtained best paper finalist award at IEEE International Symposium on System Integration for the paper on \"Closed-loop RGB-D SLAM Multi-contact Control for Humanoid Robots\""],
      "keywords": ["Humanoid Robotics", "Visual SLAM", "C++", "ROS", "mc_rtc framework", "Humanoid Robots", "Optimization", "Quadratic Programming", "Model Preview Control"],
      "url": "https://www.linkedin.com/company/cnrs/",
      "location": "Sophia-Antipolis, France | Tsukuba, Japan | Montpellier, France"
    },
    {
      "name": "Defense Advanced Research Projects Agency (DARPA)",
      "position": "DARPA Robotics Challenge Finalist",
      "startDate": "2015-06-30",
      "endDate": "2015-06-30",
      "highlights": ["Took part in major worldwide competition lead by US military research agency", "Developed robot-control strategies for disaster response scenarios, designed specifically to emulate the conditions of Fukushima nuclear plant", "Ranked 10 out of 23 leading labs"],
      "url": "https://www.linkedin.com/company/darpa/",
      "location": "United States",
      "keywords": ["International Competition", "C++", "ROS", "SLAM", "ICP", "Humanoid Robotics", "HRP-2"]
    },
    {
      "name": "Technische Universität München",
      "position": "Reasearch Internship - Loop-closure detection for SLAM",
      "startDate": "2014-03-31",
      "endDate": "2014-09-30",
      "highlights": [],
      "summary": "Place recognition using Convolutional Neural Networks (deep-learning) applied to SLAM Loop-closure detection algorithms.",
      "keywords": ["C++", "Python", "Deep Learning", "Convolutional Neural Networks", "Caffe framework", "CUDA",  "SLAM", "Loop-closure detection"],
      "url": "https://www.linkedin.com/school/technische-universitat-munchen/",
      "location": "Munich"
    },
    {
      "name": "Polytech'Nice-Sophia, Trinity College Dublin",
      "position": "University Projects",
      "startDate": "2011-12-31",
      "endDate": "2014-12-31",
      "highlights": ["3D Game Programming (physics and rendering engine)", "Interactive curve-fitting for Scanning Tunnelling Spectroscopy (Atomic Microscope)", "Distributed computing grid exploiting unused smartphone resources", "3D-Game for visually-disabled players (Project DEVINT)"],
      "keywords": ["C++", "Java", "OpenGL", "3D", "Game Development", "Computer Graphics", "Computer Science"],
      "location": "Sophia-Antipolis, France"
    },
    {
      "name": "CRANN",
      "position": "Research Internship - Scanning Tunneling Spectroscopy",
      "startDate": "2013-06-30",
      "endDate": "2013-08-31",
      "highlights": [],
      "summary": "Interactive curve-fitting for Scanning Tunneling Spectroscopy (Atomic Microscope)",
      "keywords": ["C++", "Qt", "Computer Science"],
      "url": "https://www.tcd.ie/crann/",
      "location": "Dublin, Ireland"
    },
    {
      "name": "High school",
      "position": "Developement of Fotowall",
      "startDate": "2008-12-31",
      "endDate": "2011-12-31",
      "highlights": ["Developed a popular open-source interactive image manipulation program Fotowall with an Italian partner", "Over 470, 000 downloads (as of December 2011)"],
      "url": "https://github.com/enricoros/fotowall",
      "location": "France",
      "keywords": ["C++", "Qt", "Self-taught", "git", "collaborative project", "open source"]
    }
  ],
  "volunteer": [],
  "education": [
    {
      "institution": "Laboratoire d'Informatique et de Robotique de l'Université de Montpellier - I3S Sophia-Antipolis - Joint Robotics Laboratory",
      "area": "Robotique Humanoïde, Vision par Ordinateur, SLAM",
      "studyType": "PhD in Humanoid Robotics and Computer Vision",
      "startDate": "2016-10-31",
      "endDate": "2019-10-31",
      "score": "",
      "courses": ["Humanoid Robotics", "Visual SLAM", "C++", "ROS", "mc_rtc framework", "Humanoid Robots", "Optimization", "Quadratic Programming", "Model Preview Control"]
    },
    {
      "institution": "Polytech'Nice-Sophia",
      "area": "Sciences Informatiques, Vision par ordinateur",
      "studyType": "Software Engineer (Master's degree)",
      "startDate": "2011-12-31",
      "endDate": "2014-12-31",
      "score": "",
      "courses": ["Computer Vision", "Game Development", "Java", "C++", "Computer Science", "Algorithmic", "Maths", "Languages"]
    },
    {
      "institution": "Trinity College",
      "area": "Sciences informatiques, technologies du jeux vidéo",
      "studyType": "Master's Degree in Interactive Entertainment Technologies",
      "startDate": "2012-12-31",
      "endDate": "2013-12-31",
      "score": "",
      "courses": [
        "Interactive Entertainment Technologies"
      ]
    },
    {
      "institution": "Lycée de Kérichen",
      "area": "Maths, Physique, Informatique",
      "studyType": "Classes Préparatoires aux Grandes Écoles (CPGE MPSI)",
      "startDate": "2009-12-31",
      "endDate": "2011-12-31",
      "score": "",
      "courses": ["Maths", "Physics", "Engineering", "Computer Science (Functional Programming, Algorithms, Complexity)", "Languages"]
    },
    {
      "institution": "Lycée de l’Harteloire",
      "area": "Science",
      "studyType": "Baccalauréat",
      "startDate": "2002-12-31",
      "endDate": "2009-12-31",
      "score": "Mention Bien",
      "courses": ["Maths", "Physics", "Earth and Life Sciences", "Litterature", "Phylosophy", "English", "German"]
    }
  ],
  "awards": [
    {
      "title": "Best Paper Finalist Award",
      "date": "2016-12-31",
      "awarder": "IEEE/SICE International Symposium on Industrial Informatics",
      "summary": ""
    },
    {
      "title": "DARPA Robotics Challenge Finalist as part of team AIST-NEDO",
      "date": "",
      "awarder": null,
      "summary": "Finished 10 out of 23 world-leading humanoid robotics teams."
    }
  ],
  "certificates": [],
  "publications": [
    {
      "name": "Humanoid robots in aircraft manufacturing: The airbus use cases [Best Paper Award]",
      "publisher": "IEEE Robotics & Automation Magazine",
      "releaseDate": "2019-10-31",
      "summary": "We report on the results of a collaborative project that investigated the deployment of humanoid robotic solutions in air-craft manufacturing for several assembly op erations where access by wheeled or railported robotic platforms is not possible. Recent de velopments in multicontact planning and control, bipedal walking, embedded simultaneous localization and mapping (SLAM), whole-body multisensory task-space optimization control, and contact detection and safety suggest that humanoids could be a plausible solution for automation, given the specific requirements in large-scale manufacturing sites. The main challenge is the integration of these scientific and technological advances into two existing humanoid platforms: the position-controlled Human Robotics Project (HRP-4) and the torque-controlled robot (TORO). This integration effort was demonstrated during a bracket-assembly operation inside a 1:1-scale A350 mockup of the front part of the fuselage at the Airbus Saint-Nazaire site. We present and discuss the main results achieved in this project and provide recommendations for future work.",
      "url": "https://ieeexplore.ieee.org/abstract/document/8889461"
    },
    {
      "name": "Closed-loop MPC with Dense Visual SLAM-Stability through Reactive Stepping",
      "publisher": "IEEE International Conference on Robotics and Automation",
      "releaseDate": "2019-03-31",
      "summary": "Model Predictive Control (MPC) is a widely used technique for humanoid gait generation due to its capability to handle several constraints that characterize humanoid locomotion. The use of simplified models to describe the humanoid dynamics (the Linear Inverted Pendulum) allows to perform computations in real time, giving the robot the fundamental capacity to replan its motion to follow external inputs (e.g. reference velocity, footstep plans). However, usually the MPC does not take into account the current state of the robot when computing the reference motion, losing the ability to react to external disturbances. In this paper a closed-loop MPC scheme is proposed to estimate the robot's real state through Simultaneous Localization and Mapping (SLAM) and proprioceptive sensors (force/torque). With the proposed control scheme it is shown that the robot is able to react to external disturbances (push), by stepping to recover from the loss of balance. Moreover the localization allows the robot to navigate to target positions in the environment without being affected by the drift generated by imperfect open-loop control execution. We validate the proposed scheme through two different experiments with a HRP-4 humanoid robot. ",
      "url": "https://hal.archives-ouvertes.fr/hal-01883725"
    },
    {
      "name": "Online Eye-Robot Self-Caliration",
      "publisher": "IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)",
      "releaseDate": "2018-06-11",
      "summary": "We present a new approach that extends the well known Eye-Hand calibration to the online whole-body calibration of the kinematic tree geometric parameters. Only on-board RGB-D sensor and joint encoders are required. Online calibration allows to estimate the state of the kinematic tree at any time, and thus account for inaccurate models, passive joints, mechanical wear, unexpected damages, etc. One major challenge in achieving such an online self-calibration procedure with the available sensors is that the observability of the calibrated parameters cannot always be guaranteed. In this work, we determine the effect of joint degrees of freedom on observability. From this, we propose a novel Eye-Robot calibration method that determines the geometric transformations between joints. Conditions on joint motion are further used to improve upon existing kinematic tree parameters when observability is incomplete. In practice a dense SLAM algorithm is used for online pose estimation and the results are demonstrated with an HRP-4 humanoid robot.",
      "url": "https://ieeexplore.ieee.org/abstract/document/8376273/"
    },
    {
      "name": "Closed-loop RGB-D SLAM Multi-Contact Control for humanoid robots",
      "publisher": "IEEE/SICE International Symposium on System Integration (SII)",
      "releaseDate": "2017-02-09",
      "summary": "This paper discusses the integration of a state-of-the-art dense 6D simultaneous localisation and mapping (D6DSLAM) to close the QP control loop on an humanoid robot in multi-contact motions. Our multi-contact planning defines desired contacts based on 3D (CAD) models, and generates a reaching plan. Registration of the 3D model onto an RGB-D key-frame graph representation of the explored environment allows to use of visual odometry to make real-time adjustments to the reaching plan, leading to improved in robustness from a wide range of perturbations. Extensive results are presented on various complex tasks using the HRP-2Kai humanoid robot including valve and car's steering-wheel grasping, multi-contact stair climbing from approximate initial humanoid poses.",
      "url": "https://hal.archives-ouvertes.fr/hal-01568048"
    }
  ],
  "skills": [
    {
      "name": "Humanoid robots",
      "level": "",
      "keywords": []
    },
    {
      "name": "Robot Operating System (ROS)",
      "level": "",
      "keywords": []
    },
    {
      "name": "Visual SLAM",
      "level": "",
      "keywords": []
    },
    {
      "name": "SLAM",
      "level": "",
      "keywords": []
    },
    {
      "name": "Convolutional Neural Networks (CNN)",
      "level": "",
      "keywords": []
    },
    {
      "name": "Deep Learning",
      "level": "",
      "keywords": []
    },
    {
      "name": "Caffe",
      "level": "",
      "keywords": []
    },
    {
      "name": "Physics",
      "level": "",
      "keywords": []
    },
    {
      "name": "Game Development",
      "level": "",
      "keywords": []
    },
    {
      "name": "Distributed Computing",
      "level": "",
      "keywords": []
    },
    {
      "name": "Mathematical Modeling",
      "level": "",
      "keywords": []
    },
    {
      "name": "Git",
      "level": "",
      "keywords": []
    },
    {
      "name": "GitHub",
      "level": "",
      "keywords": []
    },
    {
      "name": "mc_rtc",
      "level": "",
      "keywords": []
    },
    {
      "name": "Robotics",
      "level": "",
      "keywords": []
    },
    {
      "name": "C++",
      "level": "",
      "keywords": []
    },
    {
      "name": "OpenGL",
      "level": "",
      "keywords": []
    },
    {
      "name": "GLSL",
      "level": "",
      "keywords": []
    },
    {
      "name": "OpenCL",
      "level": "",
      "keywords": []
    },
    {
      "name": "Qt",
      "level": "",
      "keywords": []
    },
    {
      "name": "Python",
      "level": "",
      "keywords": []
    },
    {
      "name": "Java",
      "level": "",
      "keywords": []
    },
    {
      "name": "SQL",
      "level": "",
      "keywords": []
    },
    {
      "name": "Informatique",
      "level": "",
      "keywords": []
    },
    {
      "name": "Vision par ordinateur",
      "level": "",
      "keywords": []
    },
    {
      "name": "OGRE",
      "level": "",
      "keywords": []
    },
    {
      "name": "Linux",
      "level": "",
      "keywords": []
    },
    {
      "name": "Matlab",
      "level": "",
      "keywords": []
    },
    {
      "name": "C",
      "level": "",
      "keywords": []
    },
    {
      "name": "CAML",
      "level": "",
      "keywords": []
    },
    {
      "name": "Haskell",
      "level": "",
      "keywords": []
    },
    {
      "name": "Programmation",
      "level": "",
      "keywords": []
    }
  ],
  "languages": [
    {
      "language": "fr",
      "fluency": "Native Speaker"
    },
    {
      "fluency": "Native Speaker",
      "language": "English"
    },
    {
      "fluency": "Native Speaker",
      "language": "French"
    },
    {
      "fluency": "Elementary",
      "language": "German"
    }
  ],
  "interests": [],
  "references": [],
  "projects": [
    {
      "featured": true,
      "name": "mc_rtc robotics framework",
      "startDate": "2016-12-31",
      "description": "I am one of the lead developpers of the mc_rtc robotics framework. It has been used extensively at both AIST and LIRMM research labs. Notable achievements with the framework include:",
      "highlights": ["DARPA Robotic Challenge Finals",
        "COMANOID project: large scale aircraft manufacturing in partnership with Airbus", "ANA Avatar XPrize Finals", "Supports 20+ Robots (Humanoids, Manipulators and Quadrupeds)", "Walking, including stair climbing (see https://github.com/jrl-umi3218/lipm_walking_controller)", "Widely used within the research community", "Fully open-source under BSD-2"],
      "url": "https://jrl-umi3218.github.io/mc_rtc/index.html",
      "roles": ["Co-Lead Developper and Maintainer", "Implementation of industrial demonstrators", "Support for PhD and PostDocs (Paper experiments, framework development)", "Integration with robots and sensors"],
      "keywords": ["C++", "mc_rtc", "ROS", "ROS2", "Real-time Control", "Humanoid Robots", "HRP-2", "HRP-4", "HRP-5P", "Pepper", "NAO", "Sawyer", "Panda", "Kukka LWR"],
      "media":
      {
        "url": "/portfolio/featured_projects/mc_rtc.png",
        "title": "mc_rtc"
      }
    },
    {
      "name": "Robohow.Cog",
      "startDate": "2014-10-31",
      "description": "*Robohow* is a **four-year European research project** that started in February 2012. It aims at enabling robots to competently perform everyday human-scale manipulation activities - both in human working and living environments. In order to achieve this goal, *Robohow* pursues a knowledge-enabled and plan-based approach to robot programming and control. The vision of the project is that of a cognitive robot that autonomously performs complex everyday manipulation tasks and extends its repertoire of such by acquiring new skills using web-enabled and experience-based learning as well as by observing humans. ",
      "media":
      {
        "url": "/portfolio/featured_projects/robohow.png",
        "title": "Robohow.Cog"
      },
      "url": "https://robohow.org/",
      "endDate": "2015-02-28"
    },
    {
      "name": "Loop-closure detection for visual odometry (SLAM)",
      "startDate": "2014-03-31",
      "url": "/portfolio/featured_projects/rapport_stage_final_tum.pdf",
      "description": "Visual odometery consists of tracking the position and orientation of camera-like sensors as they are moving. As the camera moves, drift in the estimated camera pose can accumulate. Loop-closure detection is a technique to minimise the pose drift, by exploiting knowledge about previously visited locations. The goal of this project was to explore the feasibility of using convolutional neural networks to perform place-recognition.",
      "roles": ["Integrated Siamese Neural Networks into the Caffe deep learning framework", "Trained and evaluated the use of convolutional neural networks to perform place recognition", "Implemented a loop-closure detection algorithm in C++ and Python"],
      "media":
      {
        "url": "/portfolio/featured_projects/loop_closure.png",
        "title": "Loop-closure detection for SLAM"
      },
      "keywords": ["C++", "Python", "Deep Learning", "Convolutional Neural Networks", "Caffe framework", "CUDA",  "SLAM", "Loop-closure detection"],
      "endDate": "2014-09-30"
    },
    {
      "name": "Fotowall",
      "startDate": "2008-06-30",
      "description": "Fotowall is an opensource tool that creates patchworks with photos, text, live videos from your webcam. The development of this application helped me to build up my C++ experience along with my knowledge of the framwork Qt. It also developed my capacities of teamwork, and I learned to use project managment tools like git.",
      "url": "https://github.com/enricoros/fotowall",
      "media":
      {
        "url": "/portfolio/featured_projects/fotowall.jpg",
        "title": "Fotowall"
      },
      "endDate": "2012-03-31",
      "keywords": ["C++", "Qt", "Self-taught", "git", "collaborative project", "open source"]

    },
    {
      "name": "StartRacing - Projet DEVINT (Déficients Visuels et Nouvelles Technologies)",
      "startDate": "2012-01-31",
      "description": "3D Game implemented specifically for visually impaired people, that can be played based on listening to simulated engine sounds.",
      "url": "https://users.polytech.unice.fr/~strombon/DEVINT2015/LesProjetsDevint.html",
      "media":
      {
        "url": "/portfolio/featured_projects/start_racing.jpg",
        "title": "StartRacing"
      },
      "endDate": "2012-03-31",
      "keywords": ["Java", "OpenGL", "Game Development", "Computer Graphics", "Computer Science", "University"]

    },
    {
      "featured": true,
      "name": "Robotic Dance Performance at CDA d’Enghien",
      "description": "This **Robotic Dance Performance** was produced as part of the Co-Évolution, Co-Création et Improvisation Homme-Machine (CECCI-H2M) project of the EUR d'ArTeC, led by Pr. Chu-Yin Chen, the Image Numérique et Réalité Virtuelle (INREV) research team of the labo. AIAC of Université Paris 8, in collaboration with CDA d'Enghien-les-Bains and LIRMM Interactive Digital Human (IDH) team.",
      "location": "Centre des Arts, Enghien-les-Bains",
      "endDate": "2023",
      "keywords": ["C++", "mc_rtc", "XSens MVN", "Teleoperation", "On-stage", "Open-source"],
      "url": "https://github.com/arntanguy/CDADance",
      "media":
      {
        "url": "https://youtube.com/watch?v=iAVdj0rey5M?si=qIeUXtNo5mm854f-",
        "type": "video",
        "title": "Featured Project",
        "description": "Featured Project"
      }
    },
    {
      "featured": true,
      "name": "PhD Thesis: Visual SLAM for humanoid robot localization and closed-loop control",
      "description": "This thesis deals with the problem of localizing and controlling humanoid robots with respect to its environment, as observed by its on-board sensors. Dense visual SLAM, consisting in the simultaneous estimation of a 3D map of the environment and of the robot localization within that maps is exploited to extend and robustify multi-contact planning and control. Establishing and exploiting robot-environment contacts allows the accomplishment of both locomotion and manipulation tasks. Uncertainties in the initial robot posture, and perturbations arising from improper contact-modelling and external causes are accounted for by observing the state of the robot and its environment. A whole-body calibration method is also proposed, so that robust knowledge of the robot's kinematic structure is known, a prerequisite to all robot-environment interaction tasks. Finally, a walking method based on model predictive control is robustified by taking into account large perturbations, and adjusting the footstep and center-of-mass trajectories accordingly to guarantee stability while accomplishing desired objectives.Several experiments on an HRP-2Kai and an HRP-4 humanoid robots are presented and discussed to illustrate and validate each of the proposed methods.",
      "location": "I3S Sophia-Antipolis - LIRMM Montpellier - AIST Tskububa, Japan",
      "startDate": "2014-10",
      "endDate": "2018-11",
      "keywords": ["thesis", "SLAM", "Humanoid Robotics", "C++", "mc_rtc"],
      "url": "https://theses.fr/2018MONTS082",
      "media":
      {
        "url": "/portfolio/featured_projects/thesis.png",
        "type": "image",
        "title": "Thesis Cover"
      }
    },
    {
      "featured": true,
      "name": "ANA Avatar XPrize: Team JANUS’ cybernetic avatar system for exploration and skill transfer",
      "endDate": "2023",
      "description": "This video presents experimental results demonstrating the performance of the avatar system developed by Team JANUS to compete at the ANA Avatar XPRIZE - Finals global competition.",
      "location": "AIST, Japan - LIRMM, France - Los Angeles, USA",
      "keywords": ["Finalist", "International Competition", "mc_rtc", "humanoid robotics", "C++", "Augemented Reality", "Teleoperation", "Unity", "ANA Avatar XPRIZE"],
      "url": "https://unit.aist.go.jp/jrl-22022/en/projects/janus/team-janus.html",
      "media":
      {
        "url": "https://www.youtube.com/watch?v=CaOOoSqWjCo",
        "type": "video",
        "title": "ANA Avatar XPrize: Team JANUS’ cybernetic avatar system for exploration and skill transfer"
      }
    },
    {
      "featured": true,
      "name": "COMANOID H2020 European Project",
      "startDate": "2015-01-31",
      "endDate": "2018-12-31",
      "description": "COMANOID (Multi-Contact Collaborative Humanoids in Aircraft Manufacturing) is a RIA four-year European research project that started in January 2015 as part of the Horizon H2020 program. The project focuses on developping abilities of humanoid robots to evolve in complex enviroment -namely an aircraft fuselage- through whole body multi-contact planning motion with embeded 6D dense SLAM localization.",
      "location": "Airbus - Saint Nazaire",
      "keywords": ["Best paper award", "C++", "mc_rtc", "SLAM", "Manufacturing"],
      "roles": ["Integration of Dense Visual SLAM for Localization and Mapping within the Airplane", "Accurate Control of the Humanoid robot based on Visual SLAM"],
      "url": "https://cordis.europa.eu/article/id/386867-humanoids-may-soon-conquer-airplane-assembly",
      "media":
      {
        "url": "/portfolio/featured_projects/comanoid.jpg",
        "type": "image",
        "title": "COMANOID"
      }
    },
    {
      "featured": true,
      "name": "DARPA Robotics Challenge",
      "endDate": "2015",
      "description": "",
      "location": "Las Vegas - USA",
      "keywords": ["Finalist", "International competition", "Team AIST-NEDO", "mc_rtc", "SLAM", "Iterative Closest Point"],
      "highlights": ["Took part in major worldwide competition lead by US military research agency", 
        "Developed robot-control strategies for disaster response scenarios, designed specifically to emulate the conditions of Fukushima nuclear plant",
        "Ranked 10 out of 23 leading labs"],
      "roles": ["Localization and Mapping", "Object Registration (ICP)"],
      "url": "https://cordis.europa.eu/article/id/386867-humanoids-may-soon-conquer-airplane-assembly",
      "media":
      {
        "url": "https://www.youtube.com/watch?v=8P9geWwi9e0",
        "type": "video",
        "title": "DARPA Robotics Challenge"
      }
    },
    {
      "featured": true,
      "name": "Loco-Manipulation of Large Industrial Objects",
      "startDate": "2015-01-31",
      "endDate": "2018-12-31",
      "description": "To efficiently achieve complex humanoid loco-manipulation tasks in industrial contexts, we propose a combined vision-based tracker-localization interplay integrated as part of a task-space whole-body optimization control. To achieve good perception complementarity between manipulation and localization, a new fast dense 3D model-based tracking using wide-angle depth image is developed and used in conjunction with a simultaneous localization and mapping software. Our approach allows humanoid robots, targeted for industrial manufacturing, to manipulate and assemble large-scale objects while walking. It is assessed with experiments consisting in rolling and assembling in an unwinder a heavy and wide bobbin using bimanual grasping and bipedal locomotion at a time. This experimental use-case is found in some large-scale manufacturing where bobbins are enrolled with various materials (cables, papers, rubbers, etc.). The same experiments are made using two different humanoid robots of the same family.",
      "location": "Confidential - Industrial Factory",
      "keywords": ["C++", "mc_rtc", "SLAM", "Manufacturing"],
      "roles": ["Software Engineering for the demonstrator's implementation", "Consulting for the implementation of the Dense Visual Tracker for the Bobbin"],
      "url": "https://cordis.europa.eu/article/id/386867-humanoids-may-soon-conquer-airplane-assembly",
      "media":
      {
        "url": "/portfolio/featured_projects/bobbin.mp4",
        "type": "video",
        "title": "Bobbin Manipulation"
      }
    },
    {
      "name": "Humanoid in aircraft manufacturing: ﻿Nut Fastening with a Humanoid Robot HRP-5P",
      "endDate": "2020-10-01",
      "location": "AIST - Tsukuba - Japan",
      "keywords": ["C++", "mc_rtc", "Visual servoing", "Manufacturing"],
      "url": "https://www.youtube.com/watch?v=FT2CD1UiExs",
      "media":
      {
        "url": "https://www.youtube.com/watch?v=FT2CD1UiExs",
        "type": "video",
        "title": "HRP-5P Fastening a Nut with Visual Servoing"
      }
    },
    {
      "name": "ICRA2019 - Closed-loop MPC with Dense Visual SLAM-Stability through Reactive Stepping",
      "description": "Closed-loop MPC with Dense Visual SLAM-Stability through Reactive Stepping - Arnaud Tanguy, Daniele de Simone, Andrew Comport, Giuseppe Oriolo, Abderrahmane Kheddar",
      "featured": true,
      "endDate": "2020-10-01",
      "location": "AIST - Tsukuba - Japan",
      "keywords": ["C++", "mc_rtc", "SLAM", "Model Predictive Control"],
      "url": "https://hal.archives-ouvertes.fr/hal-01883725",
      "roles": ["Implementation of the whole demo", "Integration of the HRP-5P robot with mc_rtc"],
      "media":
      {
        "url": "https://www.youtube.com/watch?v=h38D6yRJM24",
        "type": "video",
        "title": "Closed-loop MPC with Dense Visual SLAM-Stability through Reactive Stepping Video"
      }
    },
    {
      "name": "SII 2016 - Closed-loop RGB-D SLAM Multi-Contact Control for Humanoid Robots",
      "description": "Closed-loop RGB-D SLAM multi-contact control for humanoid robots A Tanguy, P Gergondet, AI Comport, A Kheddar System Integration (SII), 2016 IEEE/SICE International Symposium on, 51-57",
      "endDate": "2016",
      "location": "AIST - Tsukuba - Japan",
      "keywords": ["Best paper finalist award", "C++", "mc_rtc", "SLAM", "Model Predictive Control", "Stair climbing", "Object manipulation"],
      "url": "https://hal.archives-ouvertes.fr/hal-01883725",
      "media":
      {
        "url": "https://www.youtube.com/watch?v=2Ch9uraz3_Y&feature=youtu.be",
        "type": "video",
        "title": "Closed-loop RGB-D SLAM Multi-Contact Control for Humanoid Robots Video"
      }
    },
    {
      "name": "Humanoid robot HRP-4 keeps balance in multi-contact and sliding scenarios",
      "description": "HRP-4 keeps balance in multi-contact while sliding its hand on a wall. To maintain balance, the robot holds its center of mass (CoM) inside a CoM support area (CSA) that takes all contacts and their contact modes into consideration. When we want to apply more force on the hand contact, the controller moves its CoM towards the wall accordingly. This video compares the performance of this control strategy with a baseline where the CoM is simply kept between the feet. Pushing and sliding operations are demonstrated.",
      "endDate": "2019",
      "location": "LIRMM - Montpellier - France",
      "keywords": ["C++", "mc_rtc", "Force Control", "Stability"],
      "url": "https://hal.science/hal-02297879",
      "roles": ["Implemantation of the demonstrator"],
      "media":
      {
        "url": "https://www.youtube.com/watch?v=Wai-Lp4e5FE",
        "type": "video",
        "title": "Humanoid robot HRP-4 keeps balance in multi-contact and sliding scenarios"
      }
    },
    {
      "name": "Humanoid Control Under Interchangeable Fixed and Sliding Unilateral Contacts",
      "description": "In this video, the HRP-4 humanoid robot demonstrates contact interchanges from fully-fixed to multi-sliding and also shuffling of the foot. This scenarios illustrate the performance of the proposed whole-body  control strategy for humanoid robots in multi-contact settings that enables switching between fixed and sliding contacts under active balance. We compute, in real-time, a safe center-of-mass position and wrench distribution of the contact points based on the Chebyshev center. Our solution is formulated as a quadratic programming problem without a priori computation of balance regions.",
      "endDate": "2021",
      "location": "LIRMM - Montpellier - France",
      "keywords": ["C++", "mc_rtc", "Force Control", "Stability"],
      "url": "https://arxiv.org/pdf/2103.02906",
      "media":
      {
        "url": "https://www.youtube.com/watch?v=cFYd9oQueRE",
        "type": "video",
        "title": "Humanoid robot HRP-4 keeps balance in multi-contact and sliding scenarios"
      }
    },
    {
      "name": "Task-Space Control Interface for SoftBank Humanoids and its Human-Robot Interaction Applications",
      "description": "In this video, we present an open-source software interface, called mc_naoqi, that allows to perform whole-body task-space Quadratic Programming based control, implemented in mc_rtc framework, on the SoftBank Robotics Europe humanoid robots. We showcase the use of the developed open-source tools for running the human-robot close contact interaction experiments with real human subjects inspired from assistance scenarios. Finally, we describe in detail the entire system including the control interface, associated robot description packages and modules and how the developed tools connect to the mc_rtc controller.",
      "endDate": "2020",
      "location": "LIRMM - Montpellier - France",
      "keywords": ["C++", "mc_rtc", "Pepper", "integration"],
      "url": "https://hal.science/hal-02919367",
      "roles": ["Integration of the robot Pepper with mc_rtc", "Help with controller implementation"],
      "media":
      {
        "url": "https://www.youtube.com/watch?v=qzEnCGlT93s",
        "type": "video",
        "title": "Task-Space Control Interface for SoftBank Humanoids and its Human-Robot Interaction Applications"
      }
    },
    {
      "name": "Impact-Aware Task-Space Quadratic-Programming Control",
      "description": "Robots usually establish contacts at rigid surfaces with near-zero relative velocities. Otherwise, impact-induced energy propagates in the robot’s linkage and may cause irreversible damage to the hardware. Moreover, abrupt changes in task-space contact velocity and peak impact forces also result in abrupt changes in robot joint velocities and torques;which can compromise controllers’ stability, especially for those based on smooth models. In reality, several tasks would require establishing contact with moderately high velocity. We propose to enhance task-space multi-objective controllers formulated as a quadratic program (QP) to be resilient to frictional impacts in three dimensions. We devise new constraints and reformulate the usual ones to be robust to the abrupt joint state changes mentioned earlier. The impact event becomes a controlled process once the optimal control search space is aware of: (1) the hardware-affordable impact bounds and (2) the analytically-computed feasible set (polyhedra) that constrain post-impact critical states. Prior to and nearby the targeted contact spot, we assume, at each control cycle, that the impact will occurat the next iteration. This somewhat one-step preview makes our controller robust to impact time and location. To assess our approach, we experimented its resilience to moderate impacts with the Panda manipulator and achieved swift grabbing tasks with the HRP-4 humanoid robot.",
      "endDate": "2022",
      "location": "LIRMM - Montpellier - France",
      "keywords": ["Paper", "C++", "mc_rtc", "HRP-4", "Logistics", "Impact"],
      "url": "https://arxiv.org/pdf/2006.01987",
      "media":
      {
        "url": "https://www.youtube.com/watch?v=78xPQ_7qM4I",
        "type": "video",
        "title": "Impact-Aware Task-Space Quadratic-Programming Control"
      }
    },
    {
      "name": "Online Object Searching by a Humanoid Robot in an Unknown Environment",
      "description": "The main video of Online Object Searching by a Humanoid Robot in an Unknown Environment, ICRA-RAL2021. M.Tsuru, A.Escande, A.Tanguy, K.Chappellet, and K.Harada, AIST, Japan.",
      "endDate": "2021-03",
      "location": "AIST - Tsukuba - Japan",
      "keywords": ["Paper", "C++", "mc_rtc", "HRP-2Kai", "SLAM", "Mapping", "Localization", "Exploration", "Object Manipulation"],
      "url": "https://ieeexplore.ieee.org/abstract/document/9361266",
      "media":
      {
        "url": "https://www.youtube.com/watch?v=2rr84jnez4k",
        "type": "video",
        "title": "Online Object Searching by a Humanoid Robot in an Unknown Environment"
      }
    }
  ],
  "robots":
  [ 
    {
      "name": "HRP-2Kai",
      "url": "/portfolio/robots/hrp2.jpg"
    },
    {
      "url": "/portfolio/robots/hrp4.jpg",
      "name": "HRP-4"
    },
    {
      "url": "/portfolio/robots/hrp4cr.jpg",
      "name": "HRP-4CR"
    },
    {
      "url": "/portfolio/robots/hrp5p.jpg",
      "name": "HRP-5P"
    },
    {
      "url": "/portfolio/robots/talos.webp",
      "name": "Talos"
    },
    {
      "url": "/portfolio/robots/nao.jpg",
      "name": "NAO"
    },
    {
      "url": "/portfolio/robots/pepper.jpg",
      "name": "Pepper"
    },
    {
      "url": "/portfolio/robots/hoap3.png",
      "name": "HOAP-3"
    },
    {
      "url": "/portfolio/robots/sawyer.jpg",
      "name": "Sawyer"
    },
    {
      "url": "/portfolio/robots/ur5e.png",
      "name": "UR5e"
    },
    {
      "url": "/portfolio/robots/panda.png",
      "name": "Panda"
    },
    {
      "url": "/portfolio/robots/bazar.jpg",
      "name": "Bazar"
    },
    {
      "url": "/portfolio/robots/fetch_image.png",
      "name": "Fetch"
    },
    {
      "url": "/portfolio/robots/aliengo.jpg",
      "name": "Aliengo"
    },
    {
      "url": "/portfolio/robots/Yaskawa_HC10DTP.webp",
      "name": "Yaskawa HC10DT"
    },
    {
      "url": "/portfolio/robots/FANUC_R-1000iA.jpg",
      "name": "FANUC R-1000iA"
    }
  ],
  "meta": {
    "version": "v1.0.0",
    "canonical": "https://github.com/jsonresume/resume-schema/blob/v1.0.0/schema.json"
  }
}
